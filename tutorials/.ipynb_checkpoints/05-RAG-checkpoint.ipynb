{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a0a075-18a7-46c7-8166-69da1a2e6981",
   "metadata": {},
   "source": [
    "# Build a Retrieval Augmented Generation (RAG) App 构建检索增强生成\n",
    "\n",
    "LLM 支持的最强大的应用程序之一是复杂的问答 (Q&A) 聊天机器人。  \n",
    "这些应用程序可以回答有关特定源信息的问题。这些应用程序使用一种称为检索增强生成 (RAG) 的技术。\n",
    "\n",
    "本教程将展示如何基于文本数据源构建一个简单的问答应用程序。在此过程中，我们将介绍典型的问答架构，并重点介绍更多高级问答技术的额外资源。  \n",
    "\n",
    "## 什么是 RAG？\n",
    "RAG 是一种通过附加数据增强 LLM 知识的技术。\n",
    "\n",
    "LLM 可以推理广泛的主题，但它们的知识仅限于在训练它们的特定时间点之前的公共数据。  \n",
    "如果您想构建能够推理私有数据或模型截止日期后引入的数据的 AI 应用程序，则需要使用模型所需的特定信息来增强模型的知识。将适当的信息插入模型提示的过程称为检索增强生成 (RAG)。\n",
    "\n",
    "LangChain 有许多组件旨在帮助构建问答应用程序，以及更普遍的 RAG 应用程序。\n",
    "\n",
    "注意：这里我们专注于非结构化数据的问答。\n",
    "\n",
    "## 概念\n",
    "典型的 RAG 应用程序有两个主要组件：\n",
    "\n",
    " - 索引：从源中提取数据并对其进行索引的管道。这通常是离线进行的。\n",
    "\n",
    " - 检索和生成：实际的 RAG 链，它在运行时接受用户查询并从索引中检索相关数据，然后将其传递给模型。\n",
    "\n",
    "从原始数据到答案的最常见完整序列如下所示：\n",
    "\n",
    "### 索引\n",
    " - 加载：首先我们需要加载数据。这可以通过 DocumentLoaders 完成。\n",
    " - 拆分：文本拆分器将大型文档拆分成较小的块。这对于索引数据和将其传递给模型都很有用，因为大块数据更难搜索，并且不适合模型的有限上下文窗口。\n",
    " - 存储：我们需要一个地方来存储和索引我们的拆分，以便以后可以搜索它们。这通常使用 VectorStore 和 Embeddings 模型来完成。\n",
    "\n",
    "### 检索和生成\n",
    " - 检索：给定用户输入，使用检索器从存储中检索相关分割。\n",
    " - 生成：ChatModel/LLM 使用包含问题和检索到的数据的提示生成答案\n",
    "\n",
    "\n",
    "让我们一步一步地分析上面的步骤。\n",
    "\n",
    "## 1. 索引：加载 （Indexing: Load）\n",
    "我们需要先加载网络文章内容。我们可以使用 DocumentLoaders 来实现这一点，它们是从源加载数据并返回文档列表的对象。Document 是一个包含一些 page_content (str) 和元数据 (dict) 的对象。\n",
    "\n",
    "在这种情况下，我们将使用 WebBaseLoader，它使用 urllib 从 Web URL 加载 HTML，并使用 BeautifulSoup 将其解析为文本。我们可以通过 bs_kwargs 将参数传递给 BeautifulSoup 解析器来自定义 HTML -> 文本解析（请参阅 BeautifulSoup 文档）。在这种情况下，只有类为“post-content”、“post-title”或“post-header”的 HTML 标签才是相关的，因此我们将删除所有其他标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "456f31ba-7827-4bb7-9aac-f68396a46093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8770"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(id=(\"article_content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://ouzhoubei.co/article-794-1.html\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "490dedca-d74d-434d-8599-23f677896797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【2024年欧洲杯小组赛A组】2024年欧洲杯德国队球员号码：1号：诺伊尔（拜仁慕尼黑）2号：吕迪格（皇家马德里）3号：劳姆（莱比锡）4号：塔（勒沃库森）5号：格罗斯（布莱顿）6号：基米希（拜仁慕尼黑）7号：哈弗茨（阿森纳）8号：克罗斯（皇马）9号：菲尔克鲁格（多特）10号：穆西亚拉（拜仁）11号：弗里希（斯图加特）12号：鲍曼（霍芬海姆）13号：穆勒（拜仁）14号：拜尔（霍芬海姆）15号：施洛特贝克（多特）16号：安东（斯图加特）17号：维尔茨（勒沃库森）18号：米特尔施塔特（斯图加特）19号：萨内（拜仁）20号：亨里希斯（莱比锡）21号：京多安（巴萨）22号：特尔施特根（巴塞罗那）23号：安德里希（勒沃库森）24号：科赫（法兰克福）25号：帕夫洛维奇（拜仁）26号：翁达夫（斯图加特）2024年欧洲杯瑞士球员号码：1号：索默（国米）2号：斯特吉奥（斯图加特）3号：威德默（美因茨）4号：埃尔维迪（门兴）5号：阿坎吉（曼城）6号：扎卡里亚（摩纳哥）7号：恩博洛（摩纳哥）8号：弗罗伊勒（博洛尼亚）9号：奥卡福（AC米兰）10号：扎卡（勒沃库森）11号：斯特芬（卢加诺）12号：姆沃戈（洛里昂\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3269076a-0e1e-4653-b137-91cf23db5189",
   "metadata": {},
   "source": [
    "## 2. 索引：拆分 ( Indexing: Split)\n",
    "我们加载的文档长度超过 8k 个字符。这太长了，无法放入许多模型的上下文窗口中。即使对于那些可以在其上下文窗口中容纳完整帖子的模型，模型也很难在非常长的输入中找到信息。\n",
    "\n",
    "为了解决这个问题，我们将文档拆分成块以进行嵌入和向量存储。这应该有助于我们在运行时仅检索博客文章中最相关的部分。\n",
    "\n",
    "在这种情况下，我们将文档拆分成 1000 个字符的块，块之间有 200 个字符的重叠。重叠有助于减轻将语句与与其相关的重要上下文分离的可能性。  \n",
    "我们使用 RecursiveCharacterTextSplitter，它将使用常用分隔符（如换行符）递归拆分文档，直到每个块的大小合适。这是针对一般文本用例的推荐文本拆分器。\n",
    "\n",
    "我们设置 add_start_index=True，以便每个拆分文档在初始文档中开始的字符索引保留为元数据属性“start_index”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8378374-500a-4c23-896a-de466d4641c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63128363-1cb0-4b37-8610-976a3338398a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c49aadb7-23b3-4757-a870-3e5d331c5fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://ouzhoubei.co/article-794-1.html', 'start_index': 7486}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[10].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fafc45-b3b8-4cf2-afff-355e37d35215",
   "metadata": {},
   "source": [
    "## 3. 索引：存储 (Indexing: Store)\n",
    "现在我们需要索引 66 个文本块，以便我们可以在运行时搜索它们。最常见的方法是嵌入每个文档拆分的内容，并将这些嵌入插入到向量数据库（或向量存储）中。  \n",
    "当我们想要搜索我们的拆分时，我们会进行文本搜索查询，嵌入它，并执行某种“相似性”搜索，以识别与我们的查询嵌入最相似的嵌入的存储拆分。  \n",
    "最简单的相似性度量是余弦相似性 - 我们测量每对嵌入（高维向量）之间角度的余弦。\n",
    "\n",
    "我们可以使用 Chroma 向量存储和 OpenAIEmbeddings 模型在单个命令中嵌入和存储所有文档拆分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65cf76a2-dee8-4cb7-8c94-4353acfe07de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取你的智谱 API Key\n",
    "# 在当前文件下创建一个.env文件，将api-key复制进去，如ZHIPUAI_API_KEY = \"api-key\"\n",
    "\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "import os \n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5841179-a1be-40f1-ba68-7739335ca0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import BaichuanTextEmbeddings\n",
    "\n",
    "embeddings = BaichuanTextEmbeddings(baichuan_api_key=os.environ[\"BAICHUAN_API_KEY\"])\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a60079-5722-4855-9095-54096b074fad",
   "metadata": {},
   "source": [
    "这样就完成了管道的索引部分。此时，我们有一个可查询的向量存储，其中包含博客文章的分块内容。给定一个用户问题，理想情况下，我们应该能够返回回答该问题的博客文章片段。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89a58ad-0b62-47c1-bfc4-7ba0ddf3df6a",
   "metadata": {},
   "source": [
    "## 4. 检索和生成：检索 (Retrieval and Generation: Retrieve)\n",
    "现在让我们编写实际的应用程序逻辑。我们想要创建一个简单的应用程序，它接受用户问题，搜索与该问题相关的文档，将检索到的文档和初始问题传递给模型，并返回答案。\n",
    "\n",
    "首先，我们需要定义搜索文档的逻辑。LangChain 定义了一个 Retriever 接口，它包装了一个索引，可以根据字符串查询返回相关文档。\n",
    "\n",
    "最常见的 Retriever 类型是 VectorStoreRetriever，它使用向量存储的相似性搜索功能来促进检索。任何 VectorStore 都可以通过 VectorStore.as_retriever() 轻松转换为 Retriever："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89d50ab1-4958-4644-ac92-0e82fe3b481a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"意大利队法乔利身披几号球衣?\")\n",
    "\n",
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faa86fa9-7689-4380-95f0-8d699691c0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "：尤克塞克（费内巴切）17号：卡维奇（费内巴切）18号：穆尔杜（费内巴切）19号：伊尔迪兹（尤文图斯）20号：卡迪奥卢（费内巴切）21号：伊尔马兹（加拉塔萨雷）22号：艾汗（加拉塔萨雷）23号：恰基尔（特拉布宗体育）24号：基里索（贝西克塔斯）25号：阿克昆（加拉塔萨雷）26号：耶尔德勒姆（雷恩）2024年欧洲杯格鲁吉亚球员号码：1号：洛里亚（第比利斯迪纳摩）2号：卡卡巴泽（克拉科夫）3号：德瓦利（希腊人竞技）4号：卡希亚（斯洛万）5号：克维尔克维利亚（阿科多）6号：科乔拉什维利（莱万特）7号：克瓦拉茨赫利亚（那不勒斯）8号：齐夫齐瓦泽（卡尔斯鲁厄）9号：达维塔什维利（波尔多）10号：查克韦塔泽（沃特福德）11号：克维利泰亚（希腊人竞技）12号：古格沙什维利（卡拉巴赫）13号：戈乔列什维利（顿涅茨克矿工）14号：洛乔什维利（克雷莫纳）15号：格维列西亚尼（波斯波利斯）16号：克维克韦斯基里（波兹南莱赫）17号：基特希什维利（斯图姆）18号：阿尔图纳什维利（沃尔夫斯贝格）19号：申格利亚（帕纳托利科斯）20号：梅克瓦比什维利（克拉约瓦）21号：齐泰什维利（第比利斯迪纳摩）22号：米卡乌塔泽（梅斯）23号：洛布贾尼泽（亚特兰大联）24号：塔比泽（帕纳托利科斯）25号：玛玛达什维利（瓦伦西亚）26号：西格亚（巴塞尔）2024年欧洲杯葡萄牙球员号码：1号：帕特里西奥（罗马）2号：塞梅多（狼队）3号：佩佩（波尔图）4号：迪亚斯（曼城）5号：达洛特（曼联）6号：帕利尼亚（富勒姆）7号：C罗（利雅得胜利）8号：B费（曼联）9号：贡萨洛·拉莫斯（巴黎）10号：B席（曼城）11号：菲利克斯（巴萨）12号：若泽·萨（狼队）13号：达尼洛·佩雷拉（巴黎）14号：伊纳西奥（葡体）15号：若昂·内维斯（本菲卡）16号：努内斯（曼城）17号：莱奥（AC米兰）18号：鲁本·内维斯（利雅得新月）19号：门德斯（巴黎）20号：坎塞洛（巴萨）21号：若塔（利物浦）22号：迪奥戈·科斯塔（波尔图）23号：维蒂尼亚（巴黎）24号：安东尼奥·席尔瓦（本菲卡）25号：内托（狼队）26号：孔塞桑（波尔图）2024年欧洲杯捷克球员号码：1号：斯塔涅克（布拉格斯拉维亚）2号：齐马（布拉格斯拉维亚）3号：霍莱什（布拉格斯拉维亚）4号：赫拉纳克（比尔森胜利）5号：曹法尔（西汉姆）6号：维蒂克（布拉格斯巴达）7号：巴拉克\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4a4a27-86fa-46bd-a95e-7c2d7dfd1f91",
   "metadata": {},
   "source": [
    "## 5. 检索和生成：生成(Retrieval and Generation: Generate)\n",
    "让我们将所有内容组合成一个链条，该链条接收问题、检索相关文档、构造提示、将其传递给模型并解析输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0ed7284-cd93-40ac-a8a5-3ba5b6db2f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://api.baichuan-ai.com/v1\",\n",
    "    api_key=os.environ[\"BAICHUAN_API_KEY\"],\n",
    "    model=\"Baichuan4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570bfbeb-8afe-45cf-8f18-40e1431af022",
   "metadata": {},
   "source": [
    "我们将使用签入 LangChain 提示中心的 RAG 提示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d24dcf30-5ab0-4232-82cf-069871087522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装langchainhub\n",
    "# pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c0d1c55-bb77-42c3-a9a0-01d938c84921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: filler question \\nContext: filler context \\nAnswer:\")]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    ").to_messages()\n",
    "\n",
    "example_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae76870-00cf-4838-81a3-e23b9249dbe0",
   "metadata": {},
   "source": [
    "我们将使用 LCEL Runnable 协议来定义链，使我们能够\n",
    "\n",
    " - 以透明的方式将组件和功能连接在一起\n",
    "\n",
    " - 开箱即用地实现流式、异步和批量调用。\n",
    "\n",
    "\n",
    "以下是实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1923f9e5-5ad2-471e-8aa0-234dbf433aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据提供的上下文，意大利队法乔利身披的球衣号码是21号。"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "for chunk in rag_chain.stream(\"意大利队法乔利身披几号球衣?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a2b8e-0546-4112-bc97-5e5ded6c3bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
