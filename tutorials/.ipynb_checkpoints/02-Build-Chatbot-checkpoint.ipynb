{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "167d7be2-b552-4d85-829a-2dc35037da38",
   "metadata": {},
   "source": [
    "# 构建聊天机器人\n",
    "## 概述\n",
    "\n",
    "我们将介绍一个示例，说明如何设计和实现基于 LLM 的聊天机器人。该聊天机器人将能够进行对话并记住之前的互动。\n",
    "\n",
    "## 概念\n",
    "\n",
    "以下是我们将要使用的一些高级组件：\n",
    " - Chat Models聊天模型。\n",
    " - Prompt Templates提示模板，简化了组合提示的过程，这些提示结合了默认消息、用户输入、聊天历史记录和（可选）其他检索到的上下文。\n",
    " - Chat History聊天历史记录，允许聊天机器人“记住”过去的互动，并在回答后续问题时将其考虑在内。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ad4a08-27e8-42d7-86b9-95166dfd450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv,find_dotenv\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a2300-079a-47ce-9506-84c2631fc622",
   "metadata": {},
   "source": [
    "# 获取你的智谱 API Key\n",
    "在当前文件下创建一个.env文件，将api-key复制进去，如ZHIPUAI_API_KEY = \"api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a831f5d0-c424-424a-86c6-c46201443a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c6d99f-5076-4792-9c65-3d62b3cdaab4",
   "metadata": {},
   "source": [
    "# Using Language Models\n",
    "\n",
    "首先，让我们学习如何单独使用语言模型。LangChain 支持多种不同的语言模型，您可以互换使用 - 在下面选择您想要使用的模型！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "709b4225-7650-4d68-8413-860434a82577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.chat_models import ChatBaichuan\n",
    "\n",
    "# model = ChatBaichuan(\n",
    "#     temperature=0.5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a0240bc-a178-4d21-8f15-b431f71a4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model = ChatOpenAI(\n",
    "#     base_url=\"https://api.baichuan-ai.com/v1\",\n",
    "#     api_key=os.environ[\"BAICHUAN_API_KEY\"],\n",
    "#     model=\"Baichuan3-Turbo\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948518a-cd98-4285-b4c7-58598837cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://open.bigmodel.cn/api/paas/v4\",\n",
    "    api_key=os.environ[\"ZHIPUAI_API_KEY\"],\n",
    "    model=\"glm-4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac74105-0620-49b0-8228-b783f79b29bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好，张三。有什么我可以帮助你的吗？', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 69, 'total_tokens': 79}, 'model_name': 'Baichuan3-Turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a3ee00ef-f515-4b60-b204-2ea41efb5673-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"你好，我叫张三。\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf13a88-bff8-4829-bb5b-67382a7eb587",
   "metadata": {},
   "source": [
    "让我们首先直接使用该模型。ChatModel 是 LangChain“Runnable”的实例，这意味着它们公开了一个用于与其交互的标准接口。为了简单地调用该模型，我们可以将消息列表传递给 .invoke 方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846242e0-8ead-4bb0-bc9e-4db8af2ebbf9",
   "metadata": {},
   "source": [
    "模型本身没有任何状态概念。例如，如果你问一个后续问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba6b715d-ee49-4309-9cd5-8b2052d75368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='对不起，我无法回答这个问题。请告诉我你的名字, 我将更好地为你服务。', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 67, 'total_tokens': 85}, 'model_name': 'Baichuan3-Turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-259dd162-4060-4783-b828-5828303ca436-0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"我的名字是什么\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b75477-3160-4c3d-a001-02f5fa54e7f1",
   "metadata": {},
   "source": [
    "为了解决这个问题，我们需要将整个对话历史记录传递到模型中。让我们看看这样做会发生什么："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5db015-ca34-43bf-8305-71ac2244c44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你的名字是张三。需要我为你做些什么吗？', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 91, 'total_tokens': 103}, 'model_name': 'Baichuan3-Turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f9d84bf5-aed7-45c3-8da7-59cd39b50c5d-0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"你好！我是张三\"),\n",
    "    AIMessage(content=\"你好，张三！请问有什么我可以帮到你的吗？\"),\n",
    "    HumanMessage(content=\"我的名字是什么\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1279718-1b6c-483a-82ee-03b1c3acbb24",
   "metadata": {},
   "source": [
    "现在我们可以看到我们得到了很好的回应！  \n",
    "\n",
    "这是聊天机器人对话式互动能力的基本理念。那么我们如何才能最好地实现这一点呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a93230a-e490-4133-9ffa-597c1ecba564",
   "metadata": {},
   "source": [
    "## Message History-消息历史记录\n",
    "\n",
    "我们可以使用消息历史记录类来包装我们的模型并使其具有状态。这将跟踪模型的输入和输出，并将它们存储在某个数据存储中。未来的交互将加载这些消息并将它们作为输入的一部分传递到链中。让我们看看如何使用它！  \n",
    "\n",
    "我们可以导入相关类并设置我们的链，该链包装模型并添加此消息历史记录。这里的关键部分是我们作为 get_session_history 传递的函数。此函数应接受 session_id 并返回消息历史记录对象。此 session_id 用于区分单独的对话，应在调用新链时作为配置的一部分传入（我们将展示如何做到这一点）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1655f699-fa27-41b2-9f7c-1666cd67d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84623285-5f70-43c9-a446-f8e50fdf44a2",
   "metadata": {},
   "source": [
    "现在我们需要创建一个配置，每次将其传递给可运行程序。此配置包含不直接属于输入但仍然有用的信息。在本例中，我们希望包含一个 session_id。这应该如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a7671ba-7b06-411d-b3d5-b619a5702657",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"session_id\":\"abc2\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c8fe669-64f0-47df-ba1a-bc31ffafc21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好，张三！有什么我可以帮助你的吗？'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"你好！我是张三\")],\n",
    "    config=config\n",
    ")\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e6812d-cda6-49bf-a7af-3ddeda61a9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你的名字是张三。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"我的名字是什么？\")],\n",
    "    config=config\n",
    ")\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176b1e32-8641-4773-82e4-e419a9f871f7",
   "metadata": {},
   "source": [
    "太棒了！我们的聊天机器人现在可以记住我们的事情了。如果我们更改配置以引用不同的 session_id，我们可以看到它会重新开始对话。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46e227b7-886e-49f8-8e27-47e461d5cc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我无法直接知道您的名字，因为您没有告诉我。请告诉我您的名字，我会很高兴为您服务。'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"session_id\":\"abc3\"\n",
    "    }\n",
    "}\n",
    "\n",
    "resp = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"我的名字是什么？\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2f07d8-6489-4133-8b23-57af5cf70e32",
   "metadata": {},
   "source": [
    "但是，我们总是可以回到原始对话（因为我们将其保存在数据库中）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "606a118a-1010-418a-840c-0c04af2780d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你的名字是张三。'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"session_id\":\"abc2\"\n",
    "    }\n",
    "}\n",
    "\n",
    "resp = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"我的名字是什么？\")],\n",
    "    config=config\n",
    ")\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4c5974-3d71-4281-bcba-95c1d7c64882",
   "metadata": {},
   "source": [
    "这就是我们如何支持聊天机器人与许多用户进行对话！  \n",
    "\n",
    "现在，我们所做的只是在模型周围添加一个简单的持久层。我们可以通过添加提示模板来开始使其变得更加复杂和个性化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d18c7c-702c-4293-8b1a-eb3a3806798a",
   "metadata": {},
   "source": [
    "## Prompt templates-提示模板\n",
    "\n",
    "提示模板有助于将原始用户信息转换为 LLM 可以使用的格式。在这种情况下，原始用户输入只是一条消息，我们将其传递给 LLM。现在让我们让它更复杂一点。首先，让我们添加一条带有一些自定义指令的系统消息（但仍然将消息作为输入）。接下来，除了消息之外，我们还将添加更多输入。  \n",
    "\n",
    "首先，让我们添加一条系统消息。为此，我们将创建一个 ChatPromptTemplate。我们将利用 MessagesPlaceholder 传递所有消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b768eac7-7027-4abe-9e16-1a93aa79c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"你是一位乐于助人的助手。尽你所能回答所有问题。\"),\n",
    "        # (\"system\",\"You are a helpful assistant. Answer all questions to the best of your ability.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1d4e86-11c6-49e8-b2aa-ef156fdb539d",
   "metadata": {},
   "source": [
    "请注意，这会稍微改变输入类型 - 而不是传递消息列表，现在我们传递一个带有消息键的字典，其中包含消息列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e8965a0-49d4-4513-9d64-23494351c810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好，王五！很高兴认识你。如果你有任何问题或需要帮助，请随时告诉我。'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = chain.invoke({\n",
    "    \"messages\":[HumanMessage(content=\"你好！我是王五\")]\n",
    "})\n",
    "\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe397ce0-a486-429f-8935-d18a6ca5f5ad",
   "metadata": {},
   "source": [
    "我们现在可以将其包装在与之前相同的消息历史记录对象中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70dedccc-bef5-4824-81be-19780051cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39866a00-048c-4fe8-9b2b-7d40011c6dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"session_id\":\"abc5\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45501bb8-0c78-416c-b482-e0cc4c170557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好，赵六！有什么我可以帮助你的吗？'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"你好！我是赵六\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c71ea20a-bf1a-4263-bc03-9d539ce2bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"我的名字是什么？\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1639746b-1974-4794-988f-77fae9ced8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你的名字是赵六。'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e782910-6a6d-4e58-82bd-0368a94a6e01",
   "metadata": {},
   "source": [
    "太棒了！现在让我们把提示变得更复杂一点。假设提示模板现在看起来像这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02fce9a9-e63c-4e8b-9ac0-686f5a4092cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"你是一个乐于助人的助手。请尽力回答所有问题并用{language}翻译.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08b0165-b477-4c44-81d1-4a63aca28a41",
   "metadata": {},
   "source": [
    "请注意，我们在提示中添加了新的language输入。现在我们可以调用链并传入我们选择的语言。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00925ae2-7bcb-43c4-9a9a-b6b9ff992cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好，张三！有什么我可以帮助你的吗？'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = chain.invoke({\n",
    "    \"messages\":[HumanMessage(content=\"你好！我是张三\")],\n",
    "    \"language\":\"日文\",\n",
    "})\n",
    "\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e811d3c-dc24-4f10-9a81-4bbc6d234cff",
   "metadata": {},
   "source": [
    "现在让我们将这个更复杂的链包装到 Message History 类中。这一次，由于输入中有多个键，我们需要指定用于保存聊天记录的正确键。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cdc4480-402f-436e-8d63-d9be6e456ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7b8bc05-20b1-4a60-a06b-192bffb293f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"session_id\":\"abc19\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6696bb0-623c-41e3-b892-f071fe058caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Здравствуйте, меня зовут Чжан Шаосан. Как я могу вам помочь сегодня?'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"你好,我是张小三。\")],\"language\":\"English英语\"},\n",
    "    config=config\n",
    ")\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffad5ca0-6a87-418f-9a56-be1cf449f19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 장소삼님입니다. 어떻게 도와 드릴까요?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"你好,我是张小三。\")],\"language\":\"韩文\"},\n",
    "    config=config\n",
    ")\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dc4036-1cb3-4faf-b0d6-bdea18b4ca4d",
   "metadata": {},
   "source": [
    "# Managing Conversation History - 管理对话历史记录\n",
    "\n",
    "构建聊天机器人时需要理解的一个重要概念是如何管理对话历史记录。如果不加以管理，消息列表将无限制增长，并可能溢出 LLM 的上下文窗口。因此，添加一个限制传入消息大小的步骤非常重要。  \n",
    "\n",
    "重要的是，您需要在提示模板之前但在从消息历史记录中加载以前的消息之后执行此操作。  \n",
    "\n",
    "我们可以通过在提示前面添加一个简单的步骤来适当修改消息键，然后将该新链包装在消息历史记录类中来实现这一点。首先，让我们定义一个将修改传入消息的函数。让我们让它选择最近的 k 条消息。然后我们可以通过在开头添加它来创建一个新链。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "75adf47d-21e4-4994-a8e9-83e84b87c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"你是一个乐于助人的助手。请尽力回答所有问题并用{language}翻译.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "def filter_messages(messages,k=10):\n",
    "    return messages[-k:]\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=lambda x: filter_messages(x[\"messages\"]))\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28154157-d983-465e-a127-b2b905b63733",
   "metadata": {},
   "source": [
    "现在让我们尝试一下！如果我们创建一个超过 10 条消息的列表，我们可以看到它不再记住早期消息中的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "138beefe-14aa-453c-8cc6-990d219926f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=\"你好，我是王小五\"),\n",
    "    AIMessage(content=\"你好!\"),\n",
    "    HumanMessage(content=\"我喜欢吃香草冰淇凌\"),\n",
    "    AIMessage(content=\"你的品味不错\"),\n",
    "    HumanMessage(content=\"2+2等于多少\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"谢谢\"),\n",
    "    AIMessage(content=\"不客气!\"),\n",
    "    HumanMessage(content=\"玩得开心吗?\"),\n",
    "    AIMessage(content=\"是的!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "157ed5f2-7b84-4754-b9c5-958a339464f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'对不起，我没有这个信息。'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"我叫什么?\")],\n",
    "        \"language\": \"日文\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3ebb5761-0d38-4eb7-95c8-3f98b57606c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你喜欢的冰淇淋口味是什么？'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"我最爱的冰淇凌口味是哪种？\")],\n",
    "        \"language\": \"韩文\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d61df-6b43-42b6-918e-b798177825b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
