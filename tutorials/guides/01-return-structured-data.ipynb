{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c7bdcb-dc4c-4736-80b9-276af788d945",
   "metadata": {},
   "source": [
    "# 如何从模型返回结构化数据 How to return structured data from a model\n",
    "\n",
    "让模型返回与特定架构匹配的输出通常很有用。  \n",
    "一个常见的用例是从文本中提取数据以插入数据库或与其他下游系统一起使用。  \n",
    "本指南介绍了从模型获取结构化输出的几种策略。\n",
    "\n",
    "## The .with_structured_output() method\n",
    "\n",
    "这是获取结构化输出的最简单、最可靠的方法。  \n",
    "with_structured_output() 是为提供用于结构化输出的本机 API 的模型实现的，例如工具/函数调用或 JSON 模式，并在后台使用这些功能。\n",
    "\n",
    "此方法将模式作为输入，该模式指定所需输出属性的名称、类型和描述。  \n",
    "该方法返回一个类似模型的 Runnable，不同之处在于它不是输出字符串或消息，而是输出与给定模式相对应的对象。  \n",
    "可以将模式指定为 JSON Schema 或 Pydantic 类。  \n",
    "如果使用 JSON Schema，则 Runnable 将返回一个字典，如果使用 Pydantic 类，则将返回 Pydantic 对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0356fca-1e40-47ef-a427-9c7637d2cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2572f5d2-6157-4ce4-aa80-3c22012640b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://open.bigmodel.cn/api/paas/v4\",\n",
    "    api_key=os.environ[\"ZHIPUAI_API_KEY\"],\n",
    "    model=\"glm-4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c24d03d-28d8-4494-97d1-1fdce72cc0ba",
   "metadata": {},
   "source": [
    "如果我们希望模型返回一个 Pydantic 对象，我们只需要传入所需的 Pydantic 类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce71974-1370-4483-bdaf-bb13f89290a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from langchain_core.pydantic_v1 import BaseModel,Field\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"告诉用户的笑话。\"\"\"\n",
    "    setup: str = Field(description=\"笑话的铺垫\")\n",
    "    punchline: str = Field(description=\"笑话的妙语\")\n",
    "    rating:Optional[int] = Field(description=\"这个笑话能打几分，从 1 到 10\")\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "564011c8-e0ae-4175-9bf7-6eed5d2b9db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='为什么猫咪总是喜欢睡觉呢？', punchline='因为它们需要保持足够的精力去捉梦中的老鼠。', rating=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm.invoke(\"给我讲一个关于猫的笑话\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5500d0cd-c663-4817-a82d-1836c4b08203",
   "metadata": {},
   "source": [
    "如果你不想使用 Pydantic，我们也可以传入 JSON Schema 字典。在这种情况下，响应也是一个字典："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77901deb-6bd7-44fa-8667-2476c3ccfce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\n",
    "    \"title\": \"笑话\",\n",
    "    \"description\": \"告诉用户的笑话。\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"setup\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"笑话的铺垫\",\n",
    "        },\n",
    "        \"punchline\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"笑话的妙语\",\n",
    "        },\n",
    "        \"rating\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"这个笑话能打几分，从 1 到 10\",\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"setup\", \"punchline\"],\n",
    "}\n",
    "\n",
    "structured_llm = llm.with_structured_output(json_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa987317-bd63-4337-a0ab-9101b34bcf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punchline': '因为它们是在梦里追老鼠啊！', 'setup': '为什么猫咪总是喜欢睡觉？'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm.invoke(\"给我讲一个关于猫的笑话\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f86c02-2c94-45bd-9c11-2e1c4308e178",
   "metadata": {},
   "source": [
    "## 在多个模式之间进行选择\n",
    "让模型从多个模式中进行选择的最简单方法是创建一个具有 Union-typed 属性的父 Pydantic 类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0caf1a34-fa48-4ce9-9731-c7ca8c40a7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "class ConversationalResponse(BaseModel):\n",
    "    \"\"\"用对话的方式回复。态度友善，乐于助人。\"\"\"\n",
    "\n",
    "    resp:str = Field(description=\"对用户的对话作出响应\")\n",
    "\n",
    "class Response(BaseModel):\n",
    "    output:Union[Joke,ConversationalResponse]\n",
    "\n",
    "structured_llm = llm.with_structured_output(Response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a63f7d21-1397-435d-9924-3b3e22bf3bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(output=Joke(setup='为什么猫咪总是喜欢把东西推下去？', punchline='因为它们是“推手”猫', rating=None))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm.invoke(\"给我讲一个关于猫的笑话\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c28688b-1f1c-4cc2-b551-b3a2669db61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output=ConversationalResponse(resp='吃了，谢谢关心！你呢？')\n"
     ]
    }
   ],
   "source": [
    "res = structured_llm.invoke(\"今天吃了吗?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d30fde0-d4bf-483e-8f23-6c064115700e",
   "metadata": {},
   "source": [
    "## 小样本提示 Few-shot prompting\n",
    "对于更复杂的模式，在提示中添加小样本示例非常有用。  \n",
    "这可以通过几种方式完成。\n",
    "\n",
    "最简单、最通用的方法是向提示中的系统消息添加示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f9eae29-3b11-4c1c-b639-bfc585d9e0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punchline': '啄木鸟会敲木头，而我只会敲门！', 'rating': 7, 'setup': '啄木鸟'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"\"\"你是一位搞笑的喜剧演员。你的专长是敲门笑话。\\\n",
    "返回一个包含铺垫（对“谁在那里？”的响应）和最终妙语（对“<setup> 谁？”的响应）的笑话。\n",
    "\n",
    "以下是一些笑话示例：\n",
    "example_user：给我讲一个关于飞机的笑话\n",
    "example_assistant：{{\"setup\": \"飞机为什么永远不会累？\", \"punchline\": \"因为它们有休息翼！\", \"rating\": 2}}\n",
    "\n",
    "example_user：给我讲另一个关于飞机的笑话\n",
    "example_assistant：{{\"setup\": \"货物\", \"punchline\": \"货物‘嗡嗡嗡’，但飞机‘嗖嗖’！\", \"rating\": 10}}\n",
    "\n",
    "example_user：现在讲讲毛毛虫\n",
    "example_assistant：{{\"setup\": \"毛毛虫\", \"punchline\": \"毛毛虫真的很慢，但看我变成蝴蝶抢尽风头！\", \"rating\": 5}}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",system),\n",
    "    (\"human\",\"{input}\")\n",
    "])\n",
    "\n",
    "few_shot_structured_llm = prompt | structured_llm\n",
    "few_shot_structured_llm.invoke(\"啄木鸟有什么好笑的？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f3e689-ede4-45fa-a6ef-908716977792",
   "metadata": {},
   "source": [
    "### 指定构造输出的方法\n",
    "\n",
    "对于支持多种结构化输出方式的模型（即它们同时支持工具调用和 JSON 模式），您可以使用 method= 参数指定要使用的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df14d350-c37f-4356-a644-043960b55d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = llm.with_structured_output(Joke, method=\"json_mode\")\n",
    "\n",
    "res = structured_llm.invoke(\n",
    "    \"Tell me a joke about cats, respond in JSON with `setup` and `punchline` keys\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1228172e-ae81-4a63-9462-9f960374e89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Joke"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07df0b91-9317-4a68-be2e-6e41bd94c16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why was the cat sitting on the computer?'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abea70d5-519d-4c2a-9f2b-aa9c5b12e2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It wanted to keep an eye on the mouse!'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.punchline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a986b5d4-4b32-4995-88d1-4025a785cb13",
   "metadata": {},
   "source": [
    "## 直接提示和解析模型\n",
    "\n",
    "并非所有模型都支持 .with_structured_output()，因为并非所有模型都具有工具调用或 JSON 模式支持。  \n",
    "对于此类模型，您需要直接提示模型使用特定格式，并使用输出解析器从原始模型输出中提取结构化响应。\n",
    "\n",
    "### 使用 PydanticOutputParser\n",
    "以下示例使用内置的 PydanticOutputParser 解析提示与给定的 Pydantic 模式匹配的聊天模型的输出。  \n",
    "请注意，我们正在从解析器上的方法直接将 format_instructions 添加到提示中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a1fd0c2-c2f0-49c2-abc1-c28bc4db793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"有关人员的信息.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"人员姓名\")\n",
    "    height_in_meters: float = Field(..., description=\"人员身高（以米为单位）\")\n",
    "\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"识别文本中所有人物的信息。\"\"\"\n",
    "\n",
    "    people: List[Person]\n",
    "\n",
    "\n",
    "# Set up a parser\n",
    "parser = PydanticOutputParser(pydantic_object=People)\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"回答用户查询。将输出包装在 `json` 标签中\\n{format_instructions}\",),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e8b7c6f-77cf-4d54-91c8-b0fd61850e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: 回答用户查询。将输出包装在 `json` 标签中\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"\\u8bc6\\u522b\\u6587\\u672c\\u4e2d\\u6240\\u6709\\u4eba\\u7269\\u7684\\u4fe1\\u606f\\u3002\", \"properties\": {\"people\": {\"title\": \"People\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Person\"}}}, \"required\": [\"people\"], \"definitions\": {\"Person\": {\"title\": \"Person\", \"description\": \"\\u6709\\u5173\\u4eba\\u5458\\u7684\\u4fe1\\u606f.\", \"type\": \"object\", \"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"\\u4eba\\u5458\\u59d3\\u540d\", \"type\": \"string\"}, \"height_in_meters\": {\"title\": \"Height In Meters\", \"description\": \"\\u4eba\\u5458\\u8eab\\u9ad8\\uff08\\u4ee5\\u7c73\\u4e3a\\u5355\\u4f4d\\uff09\", \"type\": \"number\"}}, \"required\": [\"name\", \"height_in_meters\"]}}}\n",
      "```\n",
      "Human: 小红今年 23 岁，身高 6 英尺\n"
     ]
    }
   ],
   "source": [
    "query = \"小红今年 23 岁，身高 6 英尺\"\n",
    "\n",
    "print(prompt.invoke(query).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d702e06b-7982-4c17-bfc7-79f87d37dd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='小红', height_in_meters=1.8288)])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "\n",
    "chain.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a76df-454b-417f-8d88-f4723306b912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
