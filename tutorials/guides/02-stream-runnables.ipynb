{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50198bb9-4e0c-417c-a9c1-9b435f59e24a",
   "metadata": {},
   "source": [
    "# 如何流式传输可运行文件 How to stream runnables\n",
    "\n",
    "流式传输对于使基于 LLM 的应用程序对最终用户具有响应能力至关重要。\n",
    "\n",
    "重要的 LangChain 原语（如聊天模型、输出解析器、提示、检索器和代理）实现了 LangChain Runnable 接口。\n",
    "\n",
    "此接口提供了两种流式传输内容的通用方法：\n",
    "\n",
    " - 同步流和异步流：流式传输的默认实现，可从链中流式传输最终输出。\n",
    " - 异步 astream_events 和异步 astream_log：它们提供了一种从链中流式传输中间步骤和最终输出的方法。\n",
    "   \n",
    "让我们看看这两种方法，并尝试了解如何使用它们。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89324c2c-1b1d-4190-8ab2-c92161ff0e03",
   "metadata": {},
   "source": [
    "## 使用 Stream\n",
    "所有 Runnable 对象都实现了同步方法 stream 和异步变体 astream。\n",
    "\n",
    "这些方法旨在将最终输出以块的形式流式传输，并在每个块可用时立即生成。\n",
    "\n",
    "只有当程序中的所有步骤都知道如何处理输入流时，才能进行流式传输；即一次处理一个输入块，并生成相应的输出块。\n",
    "\n",
    "此处理的复杂性各不相同，从简单的任务（如发出 LLM 生成的令牌）到更具挑战性的任务（如在整个 JSON 完成之前流式传输 JSON 结果的部分）。\n",
    "\n",
    "## LLM 和聊天模型\n",
    "大型语言模型及其聊天变体是基于 LLM 的应用程序的主要瓶颈。\n",
    "\n",
    "大型语言模型可能需要几秒钟才能生成对查询的完整响应。这比应用程序对最终用户的响应速度约 200-300 毫秒的阈值要慢得多。\n",
    "\n",
    "使应用程序感觉响应更快的关键策略是显示中间进度；即逐个标记地流式传输模型的输出。\n",
    "\n",
    "我们将展示使用聊天模型进行流式传输的示例。从以下选项中选择一个："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd712d7b-9cf7-4b64-860f-04b016c2c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3f971c6-1a41-4d5f-8152-5ca1fc4e5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"http://api.baichuan-ai.com/v1\",\n",
    "    api_key=os.environ[\"BAICHUAN_API_KEY\"],\n",
    "    model=\"Baichuan4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "493e8a85-4ae1-4a94-b0eb-afe4b3928672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "天空|的颜色取决于多种因素|，包括天气、|时间和大气中的粒子|。在晴朗的日子|，天空呈现蓝色|，这是因为大气散|射阳光中的短|波长光（|蓝光）比长|波长光（|红光）更多。|这种现象被称为瑞利|散射。\n",
      "|\n",
      "然而，天空|的颜色可以变化：|\n",
      "\n",
      "1.| 黎明和黄昏|时，天空可能|呈现红色或橙色|。这是由于太阳|在地平线附近|时，光线通过|大气层的路径更长|，导致更多的蓝光|被散射掉|，而红光和|橙光则较为|突出。\n",
      "\n",
      "|2. 在阴天|或有雾的时候，|天空可能显得灰|蒙蒙的，因为|云层或雾气|中的水滴和小颗粒|散射了所有|波长的光，|导致光线均匀地|散射，呈现出|灰色。\n",
      "\n",
      "|3. 在日落|之后或日出之前|，天空可能呈现|深蓝色甚至接近|黑色，特别是在没有|月亮和较少城市|灯光的情况下。\n",
      "|\n",
      "4. 在|极高的大气层|中，如平|流层或中间|层，天空可能会|呈现出不同的颜色，|例如在极光的|条件下，天空可能会|显现出绿色、|红色、紫色等|色彩。\n",
      "\n",
      "|总的来说，天空的颜色|是一个复杂的现象，|受到多种自然条件|的影响。|"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "for chunk in model.stream(\"天空是什么颜色?\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8114cec0-713b-4bf6-8db3-f6fbcde09491",
   "metadata": {},
   "source": [
    "或者，如果您在异步环境中工作，您可以考虑使用异步 astream API："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c70b438-cdd5-4492-b94c-fe0146f1abd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "天空|的颜色取决于多种因素|，包括时间、|天气和观察位置|。在晴朗的日子|，天空呈现出蔚|蓝色，这是因为大气|散射阳光中|较短波长的蓝光|。然而，在|日落或日出时|，天空可能呈现出|橙色、粉红色或|红色，这是由于|太阳光线穿过|大气层的路径更长|，导致较长波|长的光被散|射。此外，|阴天或多云时|，天空可能呈现出|灰白色。总之|，天空的颜色可以|变化很大，但|通常以蓝色为主|。|"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "async for chunk in model.astream(\"天空是什么颜色?\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "436962d4-1064-4cab-9c38-540401467be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='天空', id='run-780aa557-b206-4564-8c52-e5a8577b6066')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dc8e7e-3187-4cdf-af5d-88413901120e",
   "metadata": {},
   "source": [
    "## 链 Chains\n",
    "几乎所有 LLM 应用程序都涉及比调用语言模型更多的步骤。\n",
    "\n",
    "让我们使用结合了提示、模型和解析器的 LangChain 表达语言 (LCEL) 构建一个简单的链，并验证流式传输是否有效。\n",
    "\n",
    "我们将使用 StrOutputParser 来解析模型的输出。这是一个简单的解析器，它从 AIMessageChunk 中提取内容字段，为我们提供模型返回的令牌。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a702f401-2097-4a59-83e4-9842a5aab043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好的|，这里有一个关于|鹦鹉的笑话：|\n",
      "\n",
      "为什么鹦鹉|不会飞过大海|？\n",
      "\n",
      "因为它|怕水！（|注：这是一个文字|游戏，“飞|过大海”和|“喝水”在|中文里发音相近|。）|"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"给我讲一个关于{topic}的笑话\")\n",
    "parser = StrOutputParser()\n",
    "chain = prompt | model | parser\n",
    "\n",
    "async for chunk in chain.astream({\"topic\": \"鹦鹉\"}):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3178bd-c688-4eb2-adfb-1c089cc9d755",
   "metadata": {},
   "source": [
    "## 使用输入流\n",
    "如果您想在输出生成时流式传输 JSON，该怎么办？\n",
    "\n",
    "如果您依赖 json.loads 来解析部分 JSON，则解析将失败，因为部分 JSON 不是有效的 JSON。\n",
    "\n",
    "您可能会完全不知道该怎么做，并声称无法流式传输 JSON。\n",
    "\n",
    "好吧，事实证明有一种方法可以做到这一点——解析器需要对输入流进行操作，并尝试将部分 JSON“自动完成”为有效状态。\n",
    "\n",
    "让我们看看这样的解析器的实际作用，以了解这意味着什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64e7b0c8-5599-4b90-baeb-eeaef04e07a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'countries': []}\n",
      "{'countries': [{}]}\n",
      "{'countries': [{'name': 'France'}]}\n",
      "{'countries': [{'name': 'France', 'population': 6706}]}\n",
      "{'countries': [{'name': 'France', 'population': 67065000}]}\n",
      "{'countries': [{'name': 'France', 'population': 67065000}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 67065000}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 67065000}, {'name': 'Spain'}]}\n",
      "{'countries': [{'name': 'France', 'population': 67065000}, {'name': 'Spain', 'population': 467}]}\n",
      "{'countries': [{'name': 'France', 'population': 67065000}, {'name': 'Spain', 'population': 4673303}]}\n",
      "{'countries': [{'name': 'France', 'population': 67065000}, {'name': 'Spain', 'population': 46733038}]}\n",
      "{'countries': [{'name': 'France', 'population': 67065000}, {'name': 'Spain', 'population': 46733038}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 67065000}, {'name': 'Spain', 'population': 46733038}, {'name': 'Japan'}]}\n",
      "{'countries': [{'name': 'France', 'population': 67065000}, {'name': 'Spain', 'population': 46733038}, {'name': 'Japan', 'population': 12}]}\n",
      "{'countries': [{'name': 'France', 'population': 67065000}, {'name': 'Spain', 'population': 46733038}, {'name': 'Japan', 'population': 126476}]}\n",
      "{'countries': [{'name': 'France', 'population': 67065000}, {'name': 'Spain', 'population': 46733038}, {'name': 'Japan', 'population': 126476461}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain =  model | JsonOutputParser() \n",
    "async for text in chain.astream(\n",
    "    \"以 JSON 格式输出法国、西班牙和日本的国家及其人口列表。\"\n",
    "    '使用一个带有“countries”外部键的字典，其中包含国家列表。'\n",
    "    \"每个国家都应该有键`name`和`population`\"\n",
    "):\n",
    "    print(text, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c949107d-2989-41d5-a825-6945b38da8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France', 'Spain', 'Japan']|"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import (\n",
    "    JsonOutputParser,\n",
    ")\n",
    "\n",
    "# 提取国家名称\n",
    "def _extract_country_names(inputs):\n",
    "    \"\"\"A function that does not operates on input streams and breaks streaming.\"\"\"\n",
    "    if not isinstance(inputs, dict):\n",
    "        return \"\"\n",
    "\n",
    "    if \"countries\" not in inputs:\n",
    "        return \"\"\n",
    "\n",
    "    countries = inputs[\"countries\"]\n",
    "\n",
    "    if not isinstance(countries, list):\n",
    "        return \"\"\n",
    "\n",
    "    country_names = [\n",
    "        country.get(\"name\") for country in countries if isinstance(country, dict)\n",
    "    ]\n",
    "    return country_names\n",
    "\n",
    "\n",
    "chain = model | JsonOutputParser() | _extract_country_names\n",
    "\n",
    "async for text in chain.astream(\n",
    "    \"以 JSON 格式输出法国、西班牙和日本的国家及其人口列表。\"\n",
    "    '使用一个带有“countries”外部键的字典，其中包含国家列表。'\n",
    "    \"每个国家都应该有键`name`和`population`\"\n",
    "):\n",
    "    print(text, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ee087-6b03-43f1-bcfa-2ab6981d8c20",
   "metadata": {},
   "source": [
    "***生成器函数***  \n",
    "让我们使用可以对输入流进行操作的生成器函数来修复流式传输。\n",
    "\n",
    "生成器函数（使用yield的函数）允许编写对输入流进行操作的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c19ec8a8-a7dd-4e08-8ff4-1df6d9c46a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France|Spain|Japan|"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "\n",
    "async def _extract_country_names_streaming(input_stream):\n",
    "    \"\"\"A function that operates on input streams.\"\"\"\n",
    "    country_names_so_far = set()\n",
    "\n",
    "    async for input in input_stream:\n",
    "        if not isinstance(input, dict):\n",
    "            continue\n",
    "\n",
    "        if \"countries\" not in input:\n",
    "            continue\n",
    "\n",
    "        countries = input[\"countries\"]\n",
    "\n",
    "        if not isinstance(countries, list):\n",
    "            continue\n",
    "\n",
    "        for country in countries:\n",
    "            name = country.get(\"name\")\n",
    "            if not name:\n",
    "                continue\n",
    "            if name not in country_names_so_far:\n",
    "                yield name\n",
    "                country_names_so_far.add(name)\n",
    "\n",
    "\n",
    "chain = model | JsonOutputParser() | _extract_country_names_streaming\n",
    "\n",
    "async for text in chain.astream(\n",
    "    \"以 JSON 格式输出法国、西班牙和日本的国家及其人口列表。\"\n",
    "    '使用一个带有“countries”外部键的字典，其中包含国家列表。'\n",
    "    \"每个国家都应该有键`name`和`population`\"\n",
    "):\n",
    "    print(text, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d13a74-f006-424b-aaff-fa82f33a0b6f",
   "metadata": {},
   "source": [
    "## 非流式传输组件\n",
    "某些内置组件（如 Retrievers）不提供任何流式传输。如果我们尝试对它们进行流式传输，会发生什么情况？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72b948e5-173d-4dc1-b761-c98c19a37b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(page_content='张三喜欢吃辣的食物'), Document(page_content='张三曾在食为天工作过')]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain_community.embeddings import BaichuanTextEmbeddings\n",
    "\n",
    "embeddings = BaichuanTextEmbeddings(baichuan_api_key=os.environ[\"BAICHUAN_API_KEY\"])\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"张三曾在食为天工作过\",\"张三喜欢吃辣的食物\"],\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "chunks = [chunk for chunk in retriever.stream(\"张三喜欢吃什么?\")]\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2eb471de-4827-4afb-8cd3-d264d846675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = (\n",
    "    {\n",
    "        \"context\": retriever.with_config(run_name=\"Docs\"),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68af40f9-5362-4f90-bfa0-e46724017f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张三|在食为天工作|。以下是三个关于|这个地方的虚构句子|：\n",
      "\n",
      "1|. 食为|天的招牌菜是|麻辣香锅，|张三每次都会向|客人推荐这道菜。|\n",
      "2. 张|三在食为天|的工作让他有机会尝试|各种辣味菜肴|，他的味蕾因此|变得更加敏锐。\n",
      "|3. 在食|为天工作期间，张三|曾帮助餐厅研发|了一款新的辣椒酱|，这款辣椒酱|后来成为了店里的热销|产品。|"
     ]
    }
   ],
   "source": [
    "for chunk in retrieval_chain.stream(\n",
    "    \"张三在哪工作? \" \"写出 3 个关于这个地方的虚构句子。\"\n",
    "):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96435a-6191-4169-8298-3446b14c5c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
