{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a053f9c3-e42b-40a9-9f8f-0dea9f6e22e6",
   "metadata": {},
   "source": [
    "# 如何并行调用可运行组件 How to invoke runnables in parallel\n",
    "\n",
    "RunnableParallel 原语本质上是一个字典，其值是可运行对象（或可以强制转换为可运行对象的东西，如函数）。  \n",
    "它并行运行其所有值，并且每个值都使用 RunnableParallel 的整体输入进行调用。  \n",
    "最终返回值是一个字典，其每个值的结果都位于其相应的键下。\n",
    "\n",
    "## 使用 RunnableParallels 进行格式化\n",
    "RunnableParallels 对于并行化操作很有用，但也可用于操纵一个 Runnable 的输出以匹配序列中下一个 Runnable 的输入格式。  \n",
    "您可以使用它们来拆分或分叉链，以便多个组件可以并行处理输入。  \n",
    "稍后，其他组件可以连接或合并结果以合成最终响应。这种类型的链会创建一个如下所示的计算图："
   ]
  },
  {
   "cell_type": "raw",
   "id": "a833ca36-9f43-4942-90b5-fee2819a24ef",
   "metadata": {},
   "source": [
    "\n",
    "     Input\n",
    "      / \\\n",
    "     /   \\\n",
    " Branch1 Branch2\n",
    "     \\   /\n",
    "      \\ /\n",
    "    Combine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d221ec-1517-41fa-ac6b-034d6b32b7dd",
   "metadata": {},
   "source": [
    "以下内容中，传递给`prompt`的输入预期是一个包含\"context\"和\"question\"两个键的映射（map）。  \n",
    "用户输入仅仅是问题部分。所以我们需要用我们的检索器获取上下文，并将用户的输入作为\"question\"键下的内容传递进去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b40c9e-b984-49f5-b21e-2c9ce6db8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a691fc-004d-40ae-abac-a258bc84a1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'根据文档内容，张三在食为天工作。'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import BaichuanTextEmbeddings\n",
    "\n",
    "embeddings = BaichuanTextEmbeddings(baichuan_api_key=os.environ[\"BAICHUAN_API_KEY\"])\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"http://api.baichuan-ai.com/v1\",\n",
    "    api_key=os.environ[\"BAICHUAN_API_KEY\"],\n",
    "    model=\"Baichuan4\"\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_texts([\"张三在食为天工作\"],embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "template = \"\"\"请仅根据以下上下文回答问题：\n",
    "{context}\n",
    "\n",
    "问题：{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\"context\":retriever,\"question\":RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "retrieval_chain.invoke(\"张三在哪工作?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86f1846-d36c-4a61-b0e0-d6d1dacd9032",
   "metadata": {},
   "source": [
    "请注意，当将 RunnableParallel 与另一个 Runnable 组合时，我们甚至不需要将字典包装在 RunnableParallel 类中 ,类型转换已经为我们处理好了。  \n",
    "在链式结构的上下文中，以下两种方式是等效的：\n",
    "\n",
    "```python\n",
    "{\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "```\n",
    "\n",
    "```python\n",
    "RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "```\n",
    "\n",
    "```python\n",
    "RunnableParallel(context=retriever, question=RunnablePassthrough())\n",
    "```\n",
    "\n",
    "```python\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()}).invoke(\"张三在哪工作?\")\n",
    "RunnableParallel(context=retriever, question=RunnablePassthrough()).invoke(\"张三在哪工作?\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1352054-28af-40e6-a199-b55383c8a183",
   "metadata": {},
   "source": [
    "## 使用itemgetter作为简写\n",
    "请注意，当与RunnableParallel结合使用时，您可以使用Python的itemgetter作为从映射中提取数据的简写方式。  \n",
    "有关itemgetter的更多信息，您可以在Python文档中找到。\n",
    "\n",
    "在下面的例子中，我们使用itemgetter从映射中提取特定的键："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f08dfe76-298f-4cd8-8e9f-ffcfe2ccd4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import BaichuanTextEmbeddings\n",
    "\n",
    "embeddings = BaichuanTextEmbeddings(baichuan_api_key=os.environ[\"BAICHUAN_API_KEY\"])\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"http://api.baichuan-ai.com/v1\",\n",
    "    api_key=os.environ[\"BAICHUAN_API_KEY\"],\n",
    "    model=\"Baichuan4\"\n",
    ")\n",
    "\n",
    "\n",
    "vectorestore = FAISS.from_texts([\"张三喜欢是买辣鸡腿堡\"],embedding=embeddings)\n",
    "retriever = vectorestore.as_retriever()\n",
    "\n",
    "template = \"\"\"仅根据以下上下文回答问题：\n",
    "{context}\n",
    "\n",
    "问题：{question}\n",
    "\n",
    "使用以下语言回答：{language}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b514cb00-9f75-4ac1-a79e-37714f3d68ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'張三の味覚は辛い鶏のレギントンが好きです。'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\n",
    "        \"context\":itemgetter(\"question\") | retriever,\n",
    "        \"question\":itemgetter(\"question\"),\n",
    "        \"language\":itemgetter(\"language\")\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\":\"张三的口味是什么？\",\"language\":\"日文\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6402a5b-8123-4471-9a27-9bd1e8c24dea",
   "metadata": {},
   "source": [
    "## 并行化步骤\n",
    "RunnableParallels使得同时执行多个Runnable变得简单，并且可以将这些Runnable的输出作为一个映射（map）返回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5ead2bc-64ec-4a8c-a810-c780eedb9739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': AIMessage(content='好的，这是一个关于海燕的笑话：\\n\\n为什么海燕不会飞？\\n因为它已经飞得太高，找不到可以落脚的地方了。', response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 9, 'total_tokens': 38}, 'model_name': 'Baichuan4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-1120a472-5353-44da-bd7f-827c6eb97c6b-0', usage_metadata={'input_tokens': 9, 'output_tokens': 29, 'total_tokens': 38}),\n",
       " 'poem': AIMessage(content='海燕翱翔碧海间，\\n勇敢无畏舞长天。', response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 9, 'total_tokens': 22}, 'model_name': 'Baichuan4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-56c58ea2-a651-49c0-9589-5d2244a6eb48-0', usage_metadata={'input_tokens': 9, 'output_tokens': 13, 'total_tokens': 22})}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"http://api.baichuan-ai.com/v1\",\n",
    "    api_key=os.environ[\"BAICHUAN_API_KEY\"],\n",
    "    model=\"Baichuan4\"\n",
    ")\n",
    "\n",
    "joke_chain = ChatPromptTemplate.from_template(\"给我讲一个关于{topic}的笑话\") | model\n",
    "poem_chain = (ChatPromptTemplate.from_template(\"写一首关于{topic}的两行诗\") | model)\n",
    "\n",
    "map_chain = RunnableParallel(joke=joke_chain,poem=poem_chain)\n",
    "map_chain.invoke({\"topic\":\"海燕\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a1ee1-89b0-4a8a-8357-59f4489a98bc",
   "metadata": {},
   "source": [
    "## 并行性\n",
    "RunnableParallel 还可用于并行运行独立进程，因为映射中的每个 Runnable 都是并行执行的。  \n",
    "例如，我们可以看到我们之前的 joke_chain、poem_chain 和 map_chain 都具有大致相同的运行时间，尽管 map_chain 执行了其他两个。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8307632f-4384-4a2e-841f-16176822197a",
   "metadata": {},
   "source": [
    "### %%timeit\n",
    "\n",
    "%%timeit 是一个 Jupyter Notebook 或 IPython 环境中的魔术命令（magic command），用于测量代码单元格执行的时间。它会多次运行指定的代码块（默认情况下是数千次），然后给出平均执行时间、最慢执行时间和最快执行时间等统计信息，以此来提供代码执行效率的概览。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cc435e5-7b0f-4543-8e8a-4dff4e8e8435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.79 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "2.28 s ± 1.63 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "joke_chain.invoke({\"topic\": \"狗\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89c65c83-c27c-4228-88b5-47dacb584c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.07 s ± 123 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "poem_chain.invoke({\"topic\": \"狗\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "209ebaa0-3379-4d31-b359-0aafdc19cd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.76 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "3.07 s ± 2.4 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "map_chain.invoke({\"topic\": \"狗\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe10a0-a5af-4cc1-b295-b20eb467ca06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
