{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d563d9-087e-49b9-b84e-5f06111ac103",
   "metadata": {},
   "source": [
    "# 如何在聊天模型中使用少量示例 How to use few shot examples in chat models\n",
    "\n",
    "本指南介绍如何使用示例输入和输出提示聊天模型。  \n",
    "为模型提供一些这样的示例称为少量示例，这是一种简单但强大的指导生成方法，在某些情况下可以大大提高模型性能。\n",
    "\n",
    "关于如何最好地进行少量示例提示似乎没有达成共识，最佳提示编译可能会因模型而异。  \n",
    "因此，我们提供了少量示例提示模板（如 FewShotChatMessagePromptTemplate）作为灵活的起点，您可以根据需要修改或替换它们。\n",
    "\n",
    "少量示例提示模板的目标是根据输入动态选择示例，然后在最终提示中格式化示例以提供给模型。\n",
    "\n",
    "注意：以下代码示例仅适用于聊天模型，因为 FewShotChatMessagePromptTemplates 旨在输出格式化的聊天消息而不是纯字符串。  \n",
    "\n",
    "## 固定示例\n",
    "最基本（也是最常见）的少样本提示技术是使用固定提示示例。这样，您可以选择一个链，对其进行评估，并避免担心生产中的其他移动部件。\n",
    "\n",
    "模板的基本组成部分是：\n",
    "\n",
    " - examples：要包含在最终提示中的字典示例列表。\n",
    " - example_prompt：通过其 format_messages 方法将每个示例转换为 1 条或多条消息。一个常见示例是将每个示例转换为一条人类消息和一条 AI 消息响应，或者一条人类消息后跟一条函数调用消息。\n",
    "   \n",
    "以下是一个简单的演示。首先，定义您想要包含的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "092cdace-74eb-408e-b8b6-1540a64da81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"input\":\"2+2\",\"output\":\"4\"},\n",
    "    {\"input\":\"2+3\",\"output\":\"5\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce757d4f-9326-4b02-88d0-e128a291851f",
   "metadata": {},
   "source": [
    "接下来，将它们组装成小样本提示模板。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65ef6879-eb43-49d4-a43f-1594f9d48628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='2+2'), AIMessage(content='4'), HumanMessage(content='2+3'), AIMessage(content='5')]\n"
     ]
    }
   ],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\",\"{input}\"),\n",
    "    (\"ai\",\"{output}\")\n",
    "])\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.invoke({}).to_messages())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28da7f9-e082-4524-8f30-986659b7afdf",
   "metadata": {},
   "source": [
    "最后，我们组装最终提示，如下所示，将 few_shot_prompt 直接传递到 from_messages 工厂方法中，并将其与模型一起使用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca2a05a1-c5d6-464b-a118-a7dd40a40ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"你是一位奇妙的数学巫师。\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\",\"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08d8a83a-2fd6-48e6-b6fa-6acf680abc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv,load_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bea22562-1025-4e98-9b28-ad82f1698d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "首先，我们需要澄清一下问题。如果你是指一个具体的三角形的面积，并想要知道这个面积的平方，那么我们需要知道三角形的具体尺寸或者它的面积。如果你是指一个抽象的“三角形”作为一个数学概念的平方，那么这个表述是没有意义的，因为“三角形”不是一个可以进行平方运算的数值。\n",
      "\n",
      "所以，请提供更多的信息或具体说明你的问题。如果你是指求某个具体三角形的面积，请给出该三角形的底和高，或者其它可以用来计算面积的信息。如果你是在问其他与三角形相关的数学问题，也请详细说明。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chain = (\n",
    "    final_prompt \n",
    "    | ChatOpenAI(\n",
    "        base_url=\"http://api.baichuan-ai.com/v1\",\n",
    "        api_key=os.environ[\"BAICHUAN_API_KEY\"],\n",
    "        model=\"Baichuan4\",\n",
    "    )\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"input\":\"三角形的平方是多少？\"}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21145a-5bd1-4999-aac6-2deed59895e2",
   "metadata": {},
   "source": [
    "## 动态小样本提示\n",
    "\n",
    "有时您可能希望根据输入从整体集合中仅选择几个示例进行显示。  \n",
    "为此，您可以用 example_selector 替换传入 FewShotChatMessagePromptTemplate 的示例。  \n",
    "其他组件与上述相同！我们的动态小样本提示模板如下所示：\n",
    "\n",
    " - example_selector：负责为给定输入选择小样本示例（以及返回它们的顺序）。这些组件实现了 BaseExampleSelector 接口。一个常见示例是 vectorstore 支持的 SemanticSimilarityExampleSelector\n",
    " - example_prompt：通过其 format_messages 方法将每个示例转换为 1 条或多条消息。一个常见示例是将每个示例转换为一条人类消息和一条 AI 消息响应，或者一条人类消息后跟一条函数调用消息。\n",
    "   \n",
    "这些再次可以与其他消息和聊天模板组合以组装您的最终提示。\n",
    "\n",
    "让我们通过 SemanticSimilarityExampleSelector 来看一个示例。  \n",
    "由于此实现使用 vectorstore 根据语义相似性选择示例，因此我们首先要填充存储。  \n",
    "由于这里的基本思想是我们要搜索并返回与文本输入最相似的示例，因此我们嵌入提示示例的值而不是考虑键："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6594b519-b863-4901-9b15-63b10fea928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_community.embeddings import BaichuanTextEmbeddings\n",
    "\n",
    "embeddings = BaichuanTextEmbeddings(baichuan_api_key=os.environ[\"BAICHUAN_API_KEY\"])\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"2+2\", \"output\": \"4\"},\n",
    "    {\"input\": \"2+3\", \"output\": \"5\"},\n",
    "    {\"input\": \"2+4\", \"output\": \"6\"},\n",
    "    {\"input\": \"母牛对月亮说了什么?\", \"output\": \"什么都没说\"},\n",
    "    {\n",
    "        \"input\": \"写一首关于月亮的诗给我\",\n",
    "        \"output\": \"一首写给月亮，一首写给我自己，我们有什么资格谈论月亮？\",\n",
    "    },\n",
    "]\n",
    "\n",
    "to_vectorize = [\" \".join(example.values()) for example in examples]\n",
    "vectorstore = Chroma.from_texts(to_vectorize,embeddings,metadatas=examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bdec96-dfd1-4d4d-b6ae-dc9e57853239",
   "metadata": {},
   "source": [
    "## 创建 example_selector\n",
    "创建 vectorstore 后，我们可以创建 example_selector。  \n",
    "这里我们将单独调用它，并在其上设置 k 以仅获取最接近输入的两个示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07412812-e27c-4b78-975d-e7468faceb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': '写一首关于月亮的诗给我', 'output': '一首写给月亮，一首写给我自己，我们有什么资格谈论月亮？'},\n",
       " {'input': '写一首关于月亮的诗给我', 'output': '一首写给月亮，一首写给我自己，我们有什么资格谈论月亮？'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vectorstore,\n",
    "    k=2\n",
    ")\n",
    "# 提示模板将通过传递输入到“select_examples”方法来加载示例\n",
    "example_selector.select_examples({\"input\":\"月亮\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3549c3aa-4ba0-48a5-bd42-9134ca1e562d",
   "metadata": {},
   "source": [
    "## 创建提示模板\n",
    "我们现在使用上面创建的 example_selector 来组装提示模板。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d31315e-fcf6-42da-a9af-bb71ae2e0a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='2+3'), AIMessage(content='5'), HumanMessage(content='2+3'), AIMessage(content='5')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "\n",
    "# Define the few-shot prompt.\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    # The input variables select the values to pass to the example_selector\n",
    "    input_variables=[\"input\"],\n",
    "    example_selector=example_selector,\n",
    "    # Define how each example will be formatted.\n",
    "    # In this case, each example will become 2 messages:\n",
    "    # 1 human, and 1 AI\n",
    "    example_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.invoke(input=\"What's 3+3?\").to_messages())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb9647f-752a-486d-b0d4-bc34c0246b42",
   "metadata": {},
   "source": [
    "并且我们可以将这个小样本聊天消息提示模板传递到另一个聊天提示模板中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e0110ea-fe8b-43c1-8352-281504d9c154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='2+3'), AIMessage(content='5'), HumanMessage(content='2+3'), AIMessage(content='5')]\n"
     ]
    }
   ],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一位奇妙的数学巫师。\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.invoke(input=\"What's 3+3?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc584db-4609-4422-b75f-4a75aa01b68f",
   "metadata": {},
   "source": [
    "## 与聊天模型一起使用\n",
    "最后，您可以将模型连接到少样本提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7660d12c-20c4-415a-8999-3b79faa53e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='6', response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 117, 'total_tokens': 119}, 'model_name': 'Baichuan4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f67d7b6a-b3d3-44b7-8a1d-e8d86cf58347-0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = final_prompt | ChatOpenAI(\n",
    "        base_url=\"http://api.baichuan-ai.com/v1\",\n",
    "        api_key=os.environ[\"BAICHUAN_API_KEY\"],\n",
    "        model=\"Baichuan4\",\n",
    "    )\n",
    "\n",
    "chain.invoke({\"input\": \"What's 3+3?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30adafea-5d6a-4a86-ab12-4b37ba95eae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
