{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12745cdf-08d5-451d-9e55-fc561b261c77",
   "metadata": {},
   "source": [
    "# LangChain: Memory（记忆）\n",
    "\n",
    "当你与那些语言模型进行交互的时候，他们不会记得你之前和他进行的交流内容，这在我们构建一些应用程序（如聊天机器人）的时候，是一个很大的问题---显得不够智能！\n",
    "\n",
    "因此，在本节中我们将介绍LangChain 中的 Memory(记忆) 模块，即他是如何将先前的对话嵌入到语言模型中的，使其具有连续对话的能力\n",
    "\n",
    "当使用 LangChain 中的记忆组件时，他可以帮助保存和管理历史聊天消息，以及构建关于特定实体的知识。这些组件可以跨多轮对话存储信息，并允许在对话期间跟踪特定信息和上下文。\n",
    "\n",
    "LangChain 提供了多种记忆类型，包括：\n",
    "\n",
    " - ConversationBufferMemory\n",
    " - ConversationBufferWindowMemory\n",
    " - Entity Memory\n",
    " - Conversation Knowledge Graph Memory\n",
    " - ConversationSummaryMemory\n",
    " - ConversationSummaryBufferMemory\n",
    " - ConversationTokenBufferMemory\n",
    " - VectorStore-Backed Memory\n",
    "   \n",
    "缓冲区记忆允许保留最近的聊天消息，摘要记忆则提供了对整个对话的摘要。实体记忆则允许在多轮对话中保留有关特定实体的信息。\n",
    "\n",
    "这些记忆组件都是模块化的，可与其他组件组合使用，从而增强机器人的对话管理能力。Memory(记忆)模块可以通过简单的API调用来访问和更新，允许开发人员更轻松地实现对话历史记录的管理和维护。\n",
    "\n",
    "此次课程主要介绍其中四种记忆模块，其他模块可查看文档学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf541f0-5a09-4045-8822-8d3e7818d96d",
   "metadata": {},
   "source": [
    "## 大纲\n",
    "\n",
    " - ConversationBufferMemory（对话缓存记忆）\n",
    " - ConversationBufferWindowMemory（对话缓存窗口记忆）\n",
    "\n",
    "在LangChain中，Memory指的是大语言模型（LLM）的短期记忆。为什么是短期记忆？那是因为LLM训练好之后（获得了一些长期记忆），它的参数便不会因为用户的输入而发生改变。当用户与训练好的LLM进行对话时，LLM会暂时记住用户的输入和它已经生成的输出，以便预测之后的输出，而模型输出完毕后，它便会“遗忘”之前用户的输入和它的输出。因此，之前的这些信息只能称作为LLM的短期记忆。\n",
    "\n",
    "为了延长LLM短期记忆的保留时间，则需要借助一些外部存储方式来进行记忆，以便在用户与LLM对话中，LLM能够尽可能的知道用户与它所进行的历史对话信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18696878-708f-4247-871d-46f5feaa0b4e",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory（对话缓存记忆）\n",
    "\n",
    "这种记忆允许存储消息，然后从变量中提取消息。\n",
    "\n",
    "### 1.首先，让我们导入相关的包和 Zhipu API 秘钥\n",
    "\n",
    "#### dotenv模块使用解析：\n",
    "\n",
    " - 安装方式：pip install python-dotenv\n",
    " - load_dotenv()函数用于加载环境变量，\n",
    " - find_dotenv()函数用于寻找并定位.env文件的路径\n",
    " - 接下来的代码 _ = load_dotenv(find_dotenv()) ，通过find_dotenv()函数找到.env文件的路径，并将其作为参数传递给load_dotenv()函数。load_dotenv()函数会读取该.env文件，并将其中的环境变量加载到当前的运行环境中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af66830-6e2a-4f74-a688-e53cb4298c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771745fe-7e62-4720-ac56-23115059fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv,find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d052efc7-e7eb-451a-aa01-7e491494da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8893eb3d-4f36-47a2-8a3c-b00e93e90763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a22eb6-5c26-42f1-862b-ddc1e3f8737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatZhipuAI(temperature=0.5)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f2091a-5daf-4662-9bc5-14f837780a60",
   "metadata": {},
   "source": [
    "### 2.开始对话，第一轮\n",
    "\n",
    "当我们运行predict时，生成了一些提示，如下所见，他说“以下是人类和AI之间友好的对话，AI健谈“等等，这实际上是LangChain生成的提示，以使系统进行希望和友好的对话，并且必须保存对话，并提示了当前已完成的模型链。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7655ca65-f647-476a-8e41-10e25e3b0df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 你好，我的名字叫叶赫那英\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你好，叶赫那英！很高兴认识你。今天你想聊些什么呢？我们可以讨论文化、科技、日常生活等任何话题。如果你有任何问题，我也会尽力为你解答。'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"你好，我的名字叫叶赫那英\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70583d5f-ccde-41c0-85ab-6b130c4df72c",
   "metadata": {},
   "source": [
    "### 3.第二轮对话\n",
    "\n",
    "当我们进行下一轮对话时，他会保留上面的提示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d15d903-98f7-4433-8efb-0550eeecafb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 你好，我的名字叫叶赫那英\n",
      "AI: 你好，叶赫那英！很高兴认识你。今天你想聊些什么呢？我们可以讨论文化、科技、日常生活等任何话题。如果你有任何问题，我也会尽力为你解答。\n",
      "Human: 1+1等于几？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1+1等于2。这是一个基础的数学问题。如果你有更复杂的问题，也可以问我哦！'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"1+1等于几？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c007d1e3-fd4d-4d4a-ba25-cdd44f37869a",
   "metadata": {},
   "source": [
    "### 4.第三轮对话\n",
    "\n",
    "为了验证他是否记忆了前面的对话内容，我们让他回答前面已经说过的内容（我的名字），可以看到他确实输出了正确的名字，因此这个对话链随着往下进行会越来越长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5af259d-18df-4065-8469-91e9942cfda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 你好，我的名字叫叶赫那英\n",
      "AI: 你好，叶赫那英！很高兴认识你。今天你想聊些什么呢？我们可以讨论文化、科技、日常生活等任何话题。如果你有任何问题，我也会尽力为你解答。\n",
      "Human: 1+1等于几？\n",
      "AI: 1+1等于2。这是一个基础的数学问题。如果你有更复杂的问题，也可以问我哦！\n",
      "Human: 我的名字是啥?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你的名字是叶赫那英。如果你有其他问题或者想聊的话题，请随时告诉我！'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"我的名字是啥?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656a757d-20f1-4609-97e6-767e15c6a1e8",
   "metadata": {},
   "source": [
    "### 5.memory.buffer存储了当前为止所有的对话信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5c09fa0-5639-44d2-8a7f-d7db174827c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 你好，我的名字叫叶赫那英\n",
      "AI: 你好，叶赫那英！很高兴认识你。今天你想聊些什么呢？我们可以讨论文化、科技、日常生活等任何话题。如果你有任何问题，我也会尽力为你解答。\n",
      "Human: 1+1等于几？\n",
      "AI: 1+1等于2。这是一个基础的数学问题。如果你有更复杂的问题，也可以问我哦！\n",
      "Human: 我的名字是啥?\n",
      "AI: 你的名字是叶赫那英。如果你有其他问题或者想聊的话题，请随时告诉我！\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a10161-f326-41d2-a8de-e08d8710b660",
   "metadata": {},
   "source": [
    "### 6.也可以通过memory.load_memory_variables({})打印历史消息\n",
    "\n",
    "这里的花括号实际上是一个空字典，有一些更高级的功能，使用户可以使用更复杂的输入，但我们不会在这个短期课程中讨论它们，所以不要担心为什么这里有一个空的花括号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02337dff-16dc-4c97-beb6-1448f6845b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好，我的名字叫叶赫那英\\nAI: 你好，叶赫那英！很高兴认识你。今天你想聊些什么呢？我们可以讨论文化、科技、日常生活等任何话题。如果你有任何问题，我也会尽力为你解答。\\nHuman: 1+1等于几？\\nAI: 1+1等于2。这是一个基础的数学问题。如果你有更复杂的问题，也可以问我哦！\\nHuman: 我的名字是啥?\\nAI: 你的名字是叶赫那英。如果你有其他问题或者想聊的话题，请随时告诉我！'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a5c203-bd21-4ee8-ab0f-2adbeac7d6c6",
   "metadata": {},
   "source": [
    "### 7.添加指定的输入输出内容到记忆缓存区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06f1fab2-afdc-4818-91eb-a6d7bee75442",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10156c7-d549-469b-bc41-ac2eb3fafdb5",
   "metadata": {},
   "source": [
    "继续添加新的内容，对话历史都保存下来在了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9f9f07e-72f5-427b-b608-7e0cc8ad92ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"input\":\"你好,我是张小三\"},\n",
    "    {\"output\":\"有什么可以帮助你的吗？\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d49afba-6d4f-4fbd-8d97-1d8b353bcb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: 你好,我是张小三\\nAI: 有什么可以帮助你的吗？'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "630e0b3f-b5c8-4aea-8515-dca2ee2a48bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 你好,我是张小三\\nAI: 有什么可以帮助你的吗？'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74d4ad2-3bdb-4875-a71c-a594231c8f1f",
   "metadata": {},
   "source": [
    "当我们在使用大型语言模型进行聊天对话时，大型语言模型本身实际上是无状态的。语言模型本身并不记得到目前为止的历史对话。每次调用API结点都是独立的。\n",
    "\n",
    "聊天机器人似乎有记忆，只是因为通常有快速的代码可以向LLM提供迄今为止的完整对话以及上下文。因此，Memory可以明确地存储到目前为止的所有术语或对话。这个Memory存储器被用作输入或附加上下文到LLM中，以便它可以生成一个输出，就好像它只有在进行下一轮对话的时候，才知道之前说过什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d896ccf0-e5da-42ce-974f-90cdd8b5aa77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你的名字是张小三。有什么我可以帮你解答的问题吗？如果有任何需要帮助的事情，请尽管告诉我。'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = memory,\n",
    "    verbose = False\n",
    ")\n",
    "conversation.predict(input = \"我的名字是啥吗？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fab646-6c3a-4ec1-a3d4-4e9ba928bf00",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory（对话缓存窗口记忆）\n",
    "\n",
    "随着对话变得越来越长，所需的内存量也变得非常长。将大量的tokens发送到LLM的成本，也会变得更加昂贵,这也就是为什么API的调用费用，通常是基于它需要处理的tokens数量而收费的。\n",
    "\n",
    "针对以上问题，LangChain也提供了几种方便的memory来保存历史对话。 其中，对话缓存窗口记忆只保留一个窗口大小的对话缓存区窗口记忆。它只使用最近的n次交互。这可以用于保持最近交互的滑动窗口，以便缓冲区不会过大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c74f0457-8f5a-43bb-99d7-d8313c7172ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c3c853-bf91-4483-a022-88a37fde0d7d",
   "metadata": {},
   "source": [
    "### 1.向memory添加两轮对话，并查看记忆变量当前的记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52f8a50b-fd0a-4015-9ed0-6772420a1263",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "defcb852-c110-4bfe-8756-61c822e5907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"input\":\"你好\"},\n",
    "    {\"output\":\"什么事\"},\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"没事随便问问\"},\n",
    "    {\"output\":\"好的，有事您说话\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee8578a2-f968-40dc-aeb6-bedcf2b17ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 没事随便问问\\nAI: 好的，有事您说话'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459112b2-21f7-4ee1-aa80-c2bb8e1a5efd",
   "metadata": {},
   "source": [
    "### 2.在看一个例子，发现和上面的结果一样，只保留了一轮对话记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e158c83b-e47d-4d92-8ff4-7fe90ab7bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatZhipuAI(temperature=0.5)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = memory,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c6cdfb-b8e2-426d-ad54-f919674ea3b6",
   "metadata": {},
   "source": [
    "### 3.将对话缓存窗口记忆应用到对话链中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fd59339-3bce-4463-bef8-fd4ffdb209d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好，叶赫那英！很高兴认识你。今天你想聊些什么呢？无论是生活中的琐事，还是你感兴趣的知识点，我都愿意和你分享交流。如果你有任何问题，也可以直接问我，我会尽力为你提供详细的答案。'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"你好，我的名字叫叶赫那英\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb29b067-2cd8-4a26-9756-dd615505dc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1等于2。这是一个基础的数学问题。如果你有更复杂或者更有趣的问题，也欢迎继续提问！'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"1+1等于几？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe76ef-23db-4a54-9078-ccb9a8d91476",
   "metadata": {},
   "source": [
    "注意此处！由于这里用的是一个窗口的记忆，因此只能保存一轮的历史消息，因此AI并不能知道你第一轮对话中提到的名字，他最多只能记住上一轮（第二轮）的对话信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8eb80148-3646-4d9e-89e7-348b2c85efd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'作为人工智能助手，我没有持久的记忆能力来记住用户的个人信息，除非在特定的应用场景中，这些信息被明确地提供并允许存储以提供个性化服务。所以，我的回答会是：\\n\\nAI: 对不起，我没有记住你的名字。由于隐私保护和数据安全的原因，我无法存储个人信息。如果你愿意告诉我，我可以在这个对话中使用你的名字。'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"还记得我的名字吗?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7ca5ca-0417-45e7-9c2d-56c85f3063ef",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory（对话token缓存记忆）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3464d0cc-4458-476b-8b91-7814bd68cb4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio\n",
    "\n",
    "# 下面这段需要访问 huggingface\n",
    "# from langchain.memory import ConversationTokenBufferMemory\n",
    "# llm = ChatZhipuAI(temperature=0.0)\n",
    "# memory = ConversationTokenBufferMemory(llm=llm,max_token_limit=50)\n",
    "# memory.save_context({\"input\":\"AI是什么？\"},{\"output\":\"机器学习人工智能\"})\n",
    "# memory.save_context({\"input\":\"反向传播是什么？\"},{\"output\":\"是导数中的链式传导\"})\n",
    "# memory.save_context({\"input\":\"我是歌手第二期好看吗？\"},{\"output\":\"我还没看呢\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db53d4-ec30-4436-8df0-f926a54b3bd5",
   "metadata": {},
   "source": [
    "## ConversationSummaryBufferMemory（对话摘要缓存记忆）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ed05fe3-509e-41b8-ae28-76952d22770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面这段需要访问 huggingface\n",
    "\n",
    "# from langchain.memory import ConversationSummaryBufferMemory\n",
    "# ctx = \"我是歌手第二期没什么意思，只有一首歌好听，如果你没看过可以不用看了。\"\n",
    "# llm = ChatZhipuAI(temperature=0.5)\n",
    "# memory = ConversationSummaryBufferMemory(llm=llm,max_token_limit=50)\n",
    "# memory.save_context({\"input\":\"AI是什么？\"},{\"output\":\"机器学习人工智能\"})\n",
    "# memory.save_context({\"input\":\"反向传播是什么？\"},{\"output\":\"是导数中的链式传导\"})\n",
    "# memory.save_context({\"input\":\"我是歌手第二期好看吗？\"},{\"output\":f\"{ctx}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d62568-e441-4ca4-805f-e80ea58f10f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
